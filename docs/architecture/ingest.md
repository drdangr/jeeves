# Ingest: модуль загрузки и подготовки знаний

## Назначение

Модуль `Ingest` отвечает за загрузку, обработку и структурирование исходного контента (в основном — Markdown-документов), чтобы превратить его в пригодную для поиска и анализа базу знаний. Он является входной точкой всей системы RAG и формирует основу для работы Искателя и Аналитика.

---

## Задачи модуля

- Загрузка файлов из указанной директории (например, `content/`)
    
- Чанкирование (разбиение текста на смысловые блоки)
    
- Извлечение тегов и метаинформации
    
- Генерация эмбеддингов для каждого чанка
    
- Индексация чанков в векторной базе (например, Chroma + FAISS)
    
- Обновление базы при изменении исходных файлов
    

---

## Этапы обработки

### 1. Загрузка и обход файловой структуры

- Сканирование выполняется при запуске `ingest(path)` или `update_if_changed(path)`
    
- Поддерживаются форматы: `.md` (основной), опционально `.txt`, `.docx`
    
- Рекурсивный обход поддиректорий
    
- Попытка семантического сопоставления файлов с категориями (темы, персонажи, главы)
    

### 2. Чанкирование

- Используется инструмент `RecursiveCharacterTextSplitter` из библиотеки `LangChain`, адаптированный для работы с Markdown-документами
    
- Учитываются заголовки, специальные элементы и ссылки `[[...]]`
    
- Гибкая настройка: поддержка собственных разделителей, длина чанка по символам или токенам
    
- Семантический анализ позволяет объединять абзацы в логически цельные чанки
    
- В случае отсутствия структуры fallback на абзацы или маркеры
    
- Каждый чанк хранит ссылку на исходный файл и диапазон позиций (абзацы, токены)
    
- Подробнее о логике чанкирования, настройке параметров и методах оптимизации см. [[docs/architecture/ingest-chunking|документ описания чанкирования]].
    

### 3. Извлечение тегов и метаданных

- Распознавание тегов вида `#тег` и привязка их к соответствующим чанкам
    
- Извлечение ссылок `[[...]]` как индикаторов связей между документами
    
- Фиксация заголовков (`#`, `##`) как признаков тематической структуры
    
- Работа с временными метками:
    
    - Явное извлечение дат (например, `2047`, `1 января 2091`)
        
    - Перспектива: интерпретация относительных форм ("три года спустя")
        
- Попытка категоризации содержимого (темы, персонажи, локации) для поддержки дерева знаний
    

### 4. Построение графа связей

- После извлечения метаданных формируется ориентированный граф знаний.
    
- Первый слой графа строится на основе внутренних ссылок `[[...]]`, с определением направления (от источника к цели) и взвешиванием по количеству упоминаний.
    
- Второй слой графа строится на основе общих тегов между чанками, формируя тематические кластеры.
    
- Граф сохраняется для быстрой визуализации и семантической навигации (аналогично концепции двухслойного графа в Obsidian).
    
- Подробнее о структуре, форматах хранения и использовании графа см. [[docs/architecture/graph|документ описания графа связей]].
    

### 5. Генерация эмбеддингов

- Модель: `ai-forever/sbert_large_mt_nlu_ru`
    
- Библиотека: `sentence-transformers`
    
- Возможность работы локально (с GPU)
    

### 6. Индексация и хранение

- Используется `ChromaDB` с бэкендом `FAISS` — обеспечивает быстрый векторный поиск и поддержку расширенной метаинформации
    
- Для каждого чанка сохраняются:
    
    - текст,
        
    - эмбеддинг,
        
    - источник (файл),
        
    - позиция в документе,
        
    - теги и ссылки,
        
    - дата, UUID или хеш для контроля изменений
        

---

## Обновление и синхронизация

### Отслеживание изменений

- Для каждого файла сохраняются: хеш и дата последней модификации
    
- При вызове `ingest()` или `update_if_changed()` сравниваются актуальные значения
    

### Триггеры обновления

- Кнопка в интерфейсе: «Обновить базу данных»
    
- Автозапуск при старте Дживса
    
- Вызов от модуля [[docs/architecture/learner|Learner]] при правках пользователем
    

### Алгоритм обновления

- Выявление изменившихся или новых файлов
    
- Удаление старых векторов и метаданных, связанных с ними
    
- Повторная обработка: чанкирование, эмбеддинги, индексирование
    
- Обновление локальной базы
    

---

## Интерфейс взаимодействия

```python
ingest(path: str) -> List[Chunk]  # Полная инициализация базы
update_if_changed(path: str)       # Частичное обновление при изменениях
```

---

## Используется в

- [[docs/architecture/seeker|Seeker]] — поиск и фильтрация фрагментов знаний
    
- [[docs/architecture/analyst|Analyst]] — логическая обработка и выводы
    
- [[docs/architecture/interface|Interface]] — отображение связанного документа, тегов, графа